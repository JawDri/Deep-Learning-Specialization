KEY CONCEPTS
* Recall that different types of initializations lead to different results
* Recognize the importance of initialization in complex neural networks.
* Recognize the difference between train/dev/test sets
* Diagnose the bias and variance issues in your model
* Learn when and how to use regularization methods such as dropout or L2 regularization.
* Understand experimental issues in deep learning such as Vanishing or Exploding gradients and learn how to deal with them
* Use gradient checking to verify the correctness of your backpropagation implementation
